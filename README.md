# Optimisation-et-Adaptation-des-LLM-pour-Syst-mes-Ressources-Limit-es

Contexte :
Les modèles de langage de grande taille (LLM) comme GPT, BERT, et leurs variantes sont puissants mais souvent exigeants en termes de calcul et de mémoire. Cela limite leur utilisation dans des environnements où les ressources sont contraintes, comme les appareils IoT, les drones ou les robots agricoles.

Objectif :
Développer une méthode pour adapter et optimiser les LLM afin qu'ils puissent fonctionner efficacement sur des systèmes à ressources limitées. Le projet se concentre sur la compression des modèles et leur adaptation à des cas d'usage spécifiques, comme la détection d'anomalies ou la génération d'explications pour les pannes.

